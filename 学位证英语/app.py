import streamlit as st
import json
import os
import sys
import random

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="è‹±è¯­å­¦ä½è€ƒè¯•æ¨¡æ‹Ÿç³»ç»Ÿ",
    page_icon="ðŸŽ“",
    layout="wide"
)


# ================= è¾…åŠ©å‡½æ•° =================
def get_resource_path(relative_path):
    """
    èŽ·å–èµ„æºæ–‡ä»¶çš„ç»å¯¹è·¯å¾„ (å…¼å®¹æ‰“åŒ…å’Œæœ¬åœ°è¿è¡Œ)
    """
    if hasattr(sys, '_MEIPASS'):
        return os.path.join(sys._MEIPASS, relative_path)
    current_dir = os.path.dirname(os.path.abspath(__file__))
    return os.path.join(current_dir, relative_path)


def load_data(filename='data_full.json'):
    file_path = get_resource_path(filename)
    if not os.path.exists(file_path):
        st.error(f"âŒ æ‰¾ä¸åˆ°æ–‡ä»¶: {file_path}")
        return {}
    with open(file_path, 'r', encoding='utf-8') as f:
        return json.load(f)


def generate_random_paper(all_data):
    """
    æ ¸å¿ƒé€»è¾‘ï¼šä»Žæ‰€æœ‰è¯•å·ä¸­éšæœºæŠ½å–é¢˜ç›®ï¼Œç»„æˆä¸€å¥—ç¬¦åˆæ ‡å‡†ç»“æž„çš„è¯•å·
    ç»“æž„æ ‡å‡†ï¼šé˜…è¯»(4ç¯‡/20é¢˜) + è¯æ±‡(40é¢˜) + å®Œå½¢(1ç¯‡/10é¢˜) + ç¿»è¯‘(10é¢˜)
    """
    # 1. å»ºç«‹é¢˜åº“æ± 
    reading_pool = {}  # ä»¥æ–‡ç« å†…å®¹(context)ä¸ºkeyåˆ†ç»„
    vocab_pool = []
    cloze_pool = {}  # ä»¥æ–‡ç« å†…å®¹ä¸ºkeyåˆ†ç»„
    trans_pool = []

    for paper_name, questions in all_data.items():
        for q in questions:
            q_type = q.get('type')

            # é˜…è¯»ç†è§£ï¼šå¿…é¡»æŒ‰æ–‡ç« åˆ†ç»„ï¼Œä¸èƒ½æ‹†æ•£
            if q_type == 'Reading':
                ctx = q.get('context', 'no_context')
                if ctx not in reading_pool:
                    reading_pool[ctx] = []
                reading_pool[ctx].append(q)

            # å®Œå½¢å¡«ç©ºï¼šå¿…é¡»æŒ‰æ–‡ç« åˆ†ç»„
            elif q_type == 'Cloze':
                ctx = q.get('context', 'no_context')
                if ctx not in cloze_pool:
                    cloze_pool[ctx] = []
                cloze_pool[ctx].append(q)

            # è¯æ±‡é¢˜ï¼šç›´æŽ¥æ”¾å…¥å¤§æ± å­
            elif q_type == 'Vocabulary':
                vocab_pool.append(q)

            # ç¿»è¯‘é¢˜ï¼šç›´æŽ¥æ”¾å…¥å¤§æ± å­
            elif q_type == 'Translation':
                trans_pool.append(q)

    # 2. éšæœºæŠ½é¢˜ (æ¨¡æ‹Ÿæ ‡å‡†è¯•å·ç»“æž„)
    new_paper = []

    # A. æŠ½å– 4 ç¯‡é˜…è¯»ç†è§£
    all_readings = list(reading_pool.values())
    # å¦‚æžœé¢˜åº“å¤Ÿå¤šå°±æŠ½4ç¯‡ï¼Œä¸å¤Ÿå°±å…¨ä¸Š
    selected_readings = random.sample(all_readings, min(len(all_readings), 4))
    for passage_qs in selected_readings:
        new_paper.extend(passage_qs)

    # B. æŠ½å– 40 é“è¯æ±‡é¢˜
    selected_vocab = random.sample(vocab_pool, min(len(vocab_pool), 40))
    new_paper.extend(selected_vocab)

    # C. æŠ½å– 1 ç¯‡å®Œå½¢å¡«ç©º
    all_clozes = list(cloze_pool.values())
    selected_clozes = random.sample(all_clozes, min(len(all_clozes), 1))
    for passage_qs in selected_clozes:
        new_paper.extend(passage_qs)

    # D. æŠ½å– 10 é“ç¿»è¯‘é¢˜
    selected_trans = random.sample(trans_pool, min(len(trans_pool), 10))
    new_paper.extend(selected_trans)

    return new_paper


# ================= çŠ¶æ€åˆå§‹åŒ– =================
if 'current_paper_id' not in st.session_state:
    st.session_state.current_paper_id = None  # è®°å½•å½“å‰é€‰çš„æ˜¯å“ªå¥—å·ï¼ˆå­—ç¬¦ä¸²ï¼‰
if 'paper_data' not in st.session_state:
    st.session_state.paper_data = []  # å­˜å‚¨å½“å‰æ­£åœ¨åšçš„é¢˜ç›®åˆ—è¡¨
if 'question_index' not in st.session_state:
    st.session_state.question_index = 0
if 'score' not in st.session_state:
    st.session_state.score = 0
if 'answer_submitted' not in st.session_state:
    st.session_state.answer_submitted = False
if 'user_answers' not in st.session_state:
    st.session_state.user_answers = {}

# ================= ä¾§è¾¹æ  =================
st.sidebar.title("ðŸ“š è€ƒè¯•èœå•")
all_data = load_data()

# 1. æž„å»ºèœå•é€‰é¡¹
menu_options = ["ðŸŽ² éšæœºç”Ÿæˆè¯•å· (æ— é™åˆ·é¢˜)"]
if all_data:
    menu_options += list(all_data.keys())

# 2. é€‰æ‹©è¯•å·
selected_option = st.sidebar.selectbox(
    "è¯·é€‰æ‹©ç»ƒä¹ æ¨¡å¼",
    menu_options,
    index=None,
    placeholder="ç‚¹å‡»é€‰æ‹©..."
)

# 3. å¤„ç†è¯•å·åˆ‡æ¢é€»è¾‘
# å¦‚æžœç”¨æˆ·æ¢äº†é€‰é¡¹ï¼Œæˆ–è€…é€‰äº†éšæœºä¸”è¿˜æ²¡ç”Ÿæˆæ•°æ®
if selected_option != st.session_state.current_paper_id:
    if selected_option:
        # é‡ç½®æ‰€æœ‰çŠ¶æ€
        st.session_state.current_paper_id = selected_option
        st.session_state.question_index = 0
        st.session_state.score = 0
        st.session_state.answer_submitted = False
        st.session_state.user_answers = {}

        # ç”Ÿæˆé¢˜ç›®æ•°æ®
        if selected_option == "ðŸŽ² éšæœºç”Ÿæˆè¯•å· (æ— é™åˆ·é¢˜)":
            with st.spinner("æ­£åœ¨ä»Žé¢˜åº“ä¸­éšæœºç»„å·..."):
                st.session_state.paper_data = generate_random_paper(all_data)
            st.toast("âœ… æ–°çš„éšæœºè¯•å·å·²ç”Ÿæˆï¼")
        else:
            # åŠ è½½å›ºå®šè¯•å·
            st.session_state.paper_data = all_data[selected_option]

        st.rerun()

# 4. éšæœºå·çš„åˆ·æ–°æŒ‰é’®
if st.session_state.current_paper_id == "ðŸŽ² éšæœºç”Ÿæˆè¯•å· (æ— é™åˆ·é¢˜)":
    if st.sidebar.button("ðŸ”„ é‡æ–°ç”Ÿæˆä¸€å¥—éšæœºå·"):
        # æ¸…é™¤å½“å‰ ID è§¦å‘é‡æ–°ç”Ÿæˆ
        st.session_state.current_paper_id = None
        st.rerun()

# 5. é¢˜ç›®å¯¼èˆª
if st.session_state.paper_data:
    questions = st.session_state.paper_data
    total_q = len(questions)

    st.sidebar.markdown("---")
    st.sidebar.subheader("ðŸ“ é¢˜ç›®å¯¼èˆª")


    def on_nav_change():
        new_index = st.session_state.q_nav - 1
        if new_index != st.session_state.question_index:
            st.session_state.question_index = new_index
            st.session_state.answer_submitted = False


    st.sidebar.selectbox(
        "è·³è½¬åˆ°é¢˜ç›®:",
        options=range(1, total_q + 1),
        index=st.session_state.question_index,
        key="q_nav",
        on_change=on_nav_change,
        format_func=lambda x: f"ç¬¬ {x} é¢˜"
    )

    current_q_obj = questions[st.session_state.question_index]
    st.sidebar.info(f"å½“å‰é¢˜åž‹: {current_q_obj.get('type', 'æœªçŸ¥')}")

# ================= ä¸»ç•Œé¢é€»è¾‘ =================

if not st.session_state.paper_data:
    st.title("ðŸŽ“ è‹±è¯­å­¦ä½è€ƒè¯•å…¨çœŸæ¨¡æ‹Ÿç³»ç»Ÿ")
    st.markdown("""
    ### æ¬¢è¿Žä½¿ç”¨ï¼
    ðŸ‘ˆ **è¯·åœ¨å·¦ä¾§ä¾§è¾¹æ é€‰æ‹©ä¸€å¥—è¯•å·å¼€å§‹ç»ƒä¹ ã€‚**

    **ðŸ’¡ æŽ¨èå°è¯•ï¼š**
    * é€‰æ‹© **â€œðŸŽ² éšæœºç”Ÿæˆè¯•å·â€**ï¼Œç³»ç»Ÿä¼šä»Žæ‰€æœ‰é¢˜åº“ä¸­æŒ‰æ ‡å‡†æ¯”ä¾‹éšæœºæŠ½å–é¢˜ç›®ï¼Œ
      æ¯æ¬¡ç”Ÿæˆçš„è¯•å·éƒ½ä¸ä¸€æ ·ï¼Œé€‚åˆè€ƒå‰çªå‡»ï¼
    """)
else:
    # èŽ·å–å½“å‰é¢˜ç›®æ•°æ®
    questions = st.session_state.paper_data
    total_q = len(questions)
    current_idx = st.session_state.question_index
    q_data = questions[current_idx]

    # --- è€ƒè¯•ç»“æŸç•Œé¢ ---
    if current_idx >= total_q:
        st.balloons()
        st.title("ðŸŽ‰ æµ‹è¯•ç»“æŸï¼")

        # é¿å…é™¤ä»¥é›¶ï¼ˆè™½ç„¶ä¸å¤ªå¯èƒ½ï¼‰
        if total_q > 0:
            accuracy = (st.session_state.score